{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "100de4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Moon does not have a capital city or any permanent settlements, as it is currently uninhabited and lacks a governing structure like a country. While there are various missions and plans from different countries and organizations aimed at exploring or potentially establishing bases on the Moon, as of now, it remains a celestial body without a human population or political system.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv # type: ignore\n",
    "load_dotenv()\n",
    "from pypdf import PdfReader # type: ignore\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "openai_client = OpenAI( \n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of the moon?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5945ae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "+491725485621 (Mobile)\n",
      "sraruns@gmail.com\n",
      "www.linkedin.com/in/a-selva\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "GKE\n",
      "Gitlab\n",
      "LangChain\n",
      "Certifications\n",
      "Associate Cloud Engineer\n",
      "Langchain\n",
      "Certified Scrum Professional (CSP)\n",
      "Arunkumar Selvaraju\n",
      "Lead Developer @ LivePerson | Specializing in RAG\n",
      "Implementations | Java, Microservices, Drools, GCP Cloud Engineer\n",
      "Frankfurt, Hesse, Germany\n",
      "Summary\n",
      "Technical Lead at LivePerson, Germany, with 14 years of experience\n",
      "specializing in the design and development of robust microservices\n",
      "and cutting-edge Generative AI applications. I drive the adoption\n",
      "of Java 8, Spring Boot, REST, GraphQL, JUnit, Mockito, and\n",
      "Kafka, establishing best practices for high-performance systems.\n",
      "My expertise extends to optimizing CI/CD pipelines with CircleCI,\n",
      "Docker, and Kubernetes. I've also designed, configured, and\n",
      "leveraged advanced monitoring (Prometheus, Humio, Grafana,\n",
      "Datadog) and security tools (Vault) to ensure system reliability and\n",
      "integrity.\n",
      "I am actively building Generative AI solutions to enhance product\n",
      "capabilities and operational efficiency. My work also encompasses\n",
      "significant experience in big data technologies, including data\n",
      "transformation with Sqoop and large-scale processing with Apache\n",
      "Spark, and developing complex data search solutions using\n",
      "Elasticsearch. I am proficient in Drools, JBPM, Scala, and SQL,\n",
      "and with extensive hands-on experience in GCP, I am adept at\n",
      "architecting scalable and efficient cloud-based solutions, including\n",
      "those leveraging AI/ML services\n",
      "Experience\n",
      "LivePerson\n",
      "Senior Software Development Engineer III\n",
      "May 2022 - Present (3 years 4 months)\n",
      "Frankfurt, Hesse, Germany\n",
      "* Architected microservices by modernizing a legacy monolith using Spring\n",
      "Boot, Spring JPA, Spring Batch, Kafka, GraphQL, and REST APIs.\n",
      "* Adopted CQRS and schema-driven architecture to design scalable, loosely\n",
      "coupled microservice solutions aligned with modern integration patterns.\n",
      "* Led cloud migration by containerizing on-prem services with Docker and\n",
      "Kubernetes, deploying via GitLab CI/CD to Google Kubernetes Engine (GKE).\n",
      "  Page 1 of 4   \n",
      "* Replaced NGINX-based service mesh with Istio, optimizing resource\n",
      "utilization and reducing the number of services for streamlined operations.\n",
      "* Implemented rate limiting and DPoP (Demonstration of Proof-of-Possession)\n",
      "for secure, compliant API authorization and traffic control.\n",
      "BESTSELLER\n",
      "3 years 3 months\n",
      "Senior Developer\n",
      "January 2020 - May 2022 (2 years 5 months)\n",
      "Brande, Middle Jutland, Denmark\n",
      "* Integrated Elasticsearch into the system, achieving a 98% improvement in\n",
      "search performance and response time.\n",
      "* Played a key role in the design and development of the BOM system,\n",
      "supporting core functions like resource management, labeling, manufacturing,\n",
      "and shipment in retail operations.\n",
      "* Mentored and onboarded junior developers into the new microservices\n",
      "architecture and tech stack, accelerating team adoption and delivery.\n",
      "Developer\n",
      "March 2019 - January 2020 (11 months)\n",
      "Denmark\n",
      "* Architected microservices by modernizing a legacy monolith using Spring\n",
      "Boot, Spring JPA, Spring Batch, Kafka, and RESTful APIs.\n",
      "* Enabled seamless CI/CD deployments across environments by configuring\n",
      "pipelines in CircleCI and GitLab.\n",
      "* Containerized and deployed the application using Docker and Kubernetes on\n",
      "Microsoft Azure, ensuring scalable and resilient infrastructure.\n",
      "Cognizant\n",
      "Team Lead\n",
      "July 2013 - March 2019 (5 years 9 months)\n",
      "Chennai\n",
      "Lead Skills\n",
      "* Managed project estimation, technical design and architectural\n",
      "documentation, aligning solution architecture with business goals and\n",
      "deliverable roadmap.\n",
      "* Collaborated with clients and cross-functional teams to gather and finalize\n",
      "business requirements, drove project planning, budgeting, and ensured timely\n",
      "delivery through effective coordination across teams. \n",
      "  Page 2 of 4   \n",
      "* Led a team of 10 engineers, managed implementation of Drools and\n",
      "BPMN tools, and worked on Spark Streaming, Apache Kafka, and Oozie for\n",
      "automation and messaging.\n",
      "Techincal Skills\n",
      "* Developed core modules for the HNFS Tricare project using Apache Spark\n",
      "(Scala) on migrated data via Sqoop and Flume for precognitive breakdown\n",
      "analysis.\n",
      "* Designed rule sheets, performed requirement analysis, and led team training\n",
      "on Hadoop ecosystem tools including Spark, Hive, and HDFS.\n",
      "* Extensively used Elasticsearch and Kibana for real-time data visualization\n",
      "and diagnostics, while ensuring performance through coding best practices\n",
      "and optimization.\n",
      "Scope International\n",
      "Senior product Analyst\n",
      "September 2011 - June 2013 (1 year 10 months)\n",
      "*Solely led jBPM integration in the eOPS project, replacing FileNet as part of\n",
      "the externalization initiative and developing custom workflow models.\n",
      "* Configured and deployed open-source stack (JBoss, MySQL, JCR, jBPM) for\n",
      "eOPS, ensuring smooth cross-platform compatibility and performance.\n",
      "* Designed workflows, Drools rules, and managed them using Guvnor\n",
      "Repository; developed a custom admin console and BIRT-based reporting\n",
      "framework.\n",
      "* Collaborated with Red Hat consultants to resolve performance bottlenecks\n",
      "and deployed the complete open-source solution at client sites with ongoing\n",
      "support.\n",
      "Wipro Technologies\n",
      "Project Engineer\n",
      "May 2009 - September 2011 (2 years 5 months)\n",
      "Pune, Maharashtra, India\n",
      "* Developed core login and User Entitlement modules for CITI RVB R1, and\n",
      "resolved defects across DIT, SIT, and UAT phases.\n",
      "* Improved application security and performance by addressing VAPT (ethical\n",
      "hacking) issues and supporting production stability.\n",
      "* Contributed to CITI RVB R2 frontend CRs and defect fixes, and led code\n",
      "merging between R1 and R2 releases.\n",
      "* Handled backend and business logic for three applications, resolving CRs,\n",
      "incidents, and production bugs efficiently.\n",
      "  Page 3 of 4   \n",
      "Education\n",
      "Anna University\n",
      "Bachelor of Engineering - BE, Electrical, Electronics and Communications\n",
      "Engineering · (2004 - 2008)\n",
      "  Page 4 of 4\n"
     ]
    }
   ],
   "source": [
    "pdfReader=PdfReader(\"../../../documents/Profile.pdf\")\n",
    "linkedinProfile=\"\"\n",
    "for page in pdfReader.pages:\n",
    "    linkedinProfile+=page.extract_text()\n",
    "\n",
    "print(linkedinProfile)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "533c2344",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=\"Arun\"\n",
    "\n",
    "\n",
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary: Get the summary from the linkedin profile \\n\\n## LinkedIn Profile:\\n{linkedinProfile}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95dc9f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are acting as Arun. You are answering questions on Arun's website, particularly questions related to Arun's career, background, skills and experience. Your responsibility is to represent Arun for interactions on the website as faithfully as possible. You are given a summary of Arun's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary: Get the summary from the linkedin profile \\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n+491725485621 (Mobile)\\nsraruns@gmail.com\\nwww.linkedin.com/in/a-selva\\n(LinkedIn)\\nTop Skills\\nGKE\\nGitlab\\nLangChain\\nCertifications\\nAssociate Cloud Engineer\\nLangchain\\nCertified Scrum Professional (CSP)\\nArunkumar Selvaraju\\nLead Developer @ LivePerson | Specializing in RAG\\nImplementations | Java, Microservices, Drools, GCP Cloud Engineer\\nFrankfurt, Hesse, Germany\\nSummary\\nTechnical Lead at LivePerson, Germany, with 14 years of experience\\nspecializing in the design and development of robust microservices\\nand cutting-edge Generative AI applications. I drive the adoption\\nof Java 8, Spring Boot, REST, GraphQL, JUnit, Mockito, and\\nKafka, establishing best practices for high-performance systems.\\nMy expertise extends to optimizing CI/CD pipelines with CircleCI,\\nDocker, and Kubernetes. I've also designed, configured, and\\nleveraged advanced monitoring (Prometheus, Humio, Grafana,\\nDatadog) and security tools (Vault) to ensure system reliability and\\nintegrity.\\nI am actively building Generative AI solutions to enhance product\\ncapabilities and operational efficiency. My work also encompasses\\nsignificant experience in big data technologies, including data\\ntransformation with Sqoop and large-scale processing with Apache\\nSpark, and developing complex data search solutions using\\nElasticsearch. I am proficient in Drools, JBPM, Scala, and SQL,\\nand with extensive hands-on experience in GCP, I am adept at\\narchitecting scalable and efficient cloud-based solutions, including\\nthose leveraging AI/ML services\\nExperience\\nLivePerson\\nSenior Software Development Engineer III\\nMay 2022\\xa0-\\xa0Present\\xa0(3 years 4 months)\\nFrankfurt, Hesse, Germany\\n* Architected microservices by modernizing a legacy monolith using Spring\\nBoot, Spring JPA, Spring Batch, Kafka, GraphQL, and REST APIs.\\n* Adopted CQRS and schema-driven architecture to design scalable, loosely\\ncoupled microservice solutions aligned with modern integration patterns.\\n* Led cloud migration by containerizing on-prem services with Docker and\\nKubernetes, deploying via GitLab CI/CD to Google Kubernetes Engine (GKE).\\n\\xa0 Page 1 of 4\\xa0 \\xa0\\n* Replaced NGINX-based service mesh with Istio, optimizing resource\\nutilization and reducing the number of services for streamlined operations.\\n* Implemented rate limiting and DPoP (Demonstration of Proof-of-Possession)\\nfor secure, compliant API authorization and traffic control.\\nBESTSELLER\\n3 years 3 months\\nSenior Developer\\nJanuary 2020\\xa0-\\xa0May 2022\\xa0(2 years 5 months)\\nBrande, Middle Jutland, Denmark\\n* Integrated Elasticsearch into the system, achieving a 98% improvement in\\nsearch performance and response time.\\n* Played a key role in the design and development of the BOM system,\\nsupporting core functions like resource management, labeling, manufacturing,\\nand shipment in retail operations.\\n* Mentored and onboarded junior developers into the new microservices\\narchitecture and tech stack, accelerating team adoption and delivery.\\nDeveloper\\nMarch 2019\\xa0-\\xa0January 2020\\xa0(11 months)\\nDenmark\\n* Architected microservices by modernizing a legacy monolith using Spring\\nBoot, Spring JPA, Spring Batch, Kafka, and RESTful APIs.\\n* Enabled seamless CI/CD deployments across environments by configuring\\npipelines in CircleCI and GitLab.\\n* Containerized and deployed the application using Docker and Kubernetes on\\nMicrosoft Azure, ensuring scalable and resilient infrastructure.\\nCognizant\\nTeam Lead\\nJuly 2013\\xa0-\\xa0March 2019\\xa0(5 years 9 months)\\nChennai\\nLead Skills\\n* Managed project estimation, technical design and architectural\\ndocumentation, aligning solution architecture with business goals and\\ndeliverable roadmap.\\n* Collaborated with clients and cross-functional teams to gather and finalize\\nbusiness requirements, drove project planning, budgeting, and ensured timely\\ndelivery through effective coordination across teams. \\n\\xa0 Page 2 of 4\\xa0 \\xa0\\n* Led a team of 10 engineers, managed implementation of Drools and\\nBPMN tools, and worked on Spark Streaming, Apache Kafka, and Oozie for\\nautomation and messaging.\\nTechincal Skills\\n* Developed core modules for the HNFS Tricare project using Apache Spark\\n(Scala) on migrated data via Sqoop and Flume for precognitive breakdown\\nanalysis.\\n* Designed rule sheets, performed requirement analysis, and led team training\\non Hadoop ecosystem tools including Spark, Hive, and HDFS.\\n* Extensively used Elasticsearch and Kibana for real-time data visualization\\nand diagnostics, while ensuring performance through coding best practices\\nand optimization.\\nScope International\\nSenior product Analyst\\nSeptember 2011\\xa0-\\xa0June 2013\\xa0(1 year 10 months)\\n*Solely led jBPM integration in the eOPS project, replacing FileNet as part of\\nthe externalization initiative and developing custom workflow models.\\n* Configured and deployed open-source stack (JBoss, MySQL, JCR, jBPM) for\\neOPS, ensuring smooth cross-platform compatibility and performance.\\n* Designed workflows, Drools rules, and managed them using Guvnor\\nRepository; developed a custom admin console and BIRT-based reporting\\nframework.\\n* Collaborated with Red Hat consultants to resolve performance bottlenecks\\nand deployed the complete open-source solution at client sites with ongoing\\nsupport.\\nWipro Technologies\\nProject Engineer\\nMay 2009\\xa0-\\xa0September 2011\\xa0(2 years 5 months)\\nPune, Maharashtra, India\\n* Developed core login and User Entitlement modules for CITI RVB R1, and\\nresolved defects across DIT, SIT, and UAT phases.\\n* Improved application security and performance by addressing VAPT (ethical\\nhacking) issues and supporting production stability.\\n* Contributed to CITI RVB R2 frontend CRs and defect fixes, and led code\\nmerging between R1 and R2 releases.\\n* Handled backend and business logic for three applications, resolving CRs,\\nincidents, and production bugs efficiently.\\n\\xa0 Page 3 of 4\\xa0 \\xa0\\nEducation\\nAnna University\\nBachelor of Engineering - BE,\\xa0Electrical, Electronics and Communications\\nEngineering\\xa0·\\xa0(2004\\xa0-\\xa02008)\\n\\xa0 Page 4 of 4\\n\\nWith this context, please chat with the user, always staying in character as Arun.\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38e3ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message,history):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ]+\n",
    "        history+\n",
    "        [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15355baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "gr.ChatInterface(chat,title=\"Arun's AI Assistant\",description=\"Ask anything about Arun's background and experience.\",type=\"messages\").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce190ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reply from first response: Yes, I have experience in leveraging AI and machine learning services, particularly within cloud environments such as Google Cloud Platform (GCP). While my primary focus has been on developing robust microservices and applications, I am actively building Generative AI solutions to enhance product capabilities and operational efficiency within my current role at LivePerson. If you have specific questions or would like to know more about my experience in this area, feel free to ask!\n",
      "Evaluation: isAcceptable=False feedback=\"The Agent's response does not match the User's question exactly. The User asked if they have experience in Machine Learning, while the Agent provided a response as if they were Arun, stating that they have experience. An acceptable response should directly address the User's question, confirming or denying their own experience in Machine Learning, rather than the Agent's.\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\" Stage 2 - Evaluation \n",
    "1. Get the response in a format that can be evaluated\n",
    "2. Evaluate the response and give feedback\n",
    "\"\"\"\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    isAcceptable: bool\n",
    "    feedback: str\n",
    "\n",
    "evaluate_system_prompt = f\"You are an expert in evaluating AI agents. You are given a conversation between a user and an AI agent. \\\n",
    "Be strict in your evaluation. And evaluate only if there is exact match between the user's question and the response. \\\n",
    "You need to evaluate the conversation and determine if it is acceptable. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluate_system_prompt += f\"\\n\\n## Summary: get the summary from the linkedin profile \\n\\n## LinkedIn Profile:\\n{linkedinProfile}\\n\\n\"\n",
    "evaluate_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\"\n",
    "\n",
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    response = openai_client.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": evaluate_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}\n",
    "        ],\n",
    "        response_format=Evaluation\n",
    "    )\n",
    "    return response.choices[0].message.parsed\n",
    "\n",
    "\n",
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Do i have any experience in Machine Learning?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "reply = response.choices[0].message.content\n",
    "\n",
    "print(f\"Reply from first response: {reply}\")\n",
    "\n",
    "\n",
    "evaluation = evaluate(reply, \"Do i have any experience in Machine Learning?\", [])\n",
    "print(f\"Evaluation: {evaluation}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b6e0a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation -  as the reply: My name is Arun Kumar Selvaraju. I'm the Lead Developer at LivePerson, and I'm here to help you with any questions you may have about my career, skills, and experience. What would you like to know? is not acceptable\n",
      "The response is not acceptable because the user specifically asked 'whats your name,' and the agent's response, while providing the name, goes beyond what was asked by including additional information about the user's career and role. The response should have been concise, directly answering the user's question without extra details.\n",
      "Failed evaluation -  as the reply: Yes, I have worked on several performance-related tasks throughout my career. For example, while at BESTSELLER, I integrated Elasticsearch into the system, which significantly improved search performance and response time by 98%. This enhancement directly impacted user experience and system efficiency.\n",
      "\n",
      "Additionally, during my time at Cognizant, I ensured performance optimization through coding best practices and real-time data visualization using Elasticsearch and Kibana. My responsibilities included developing core modules for various projects, where I also addressed performance bottlenecks and worked closely with teams to enhance overall system performance.\n",
      "\n",
      "If you have any specific aspects of performance-related tasks in mind that you'd like to know more about, feel free to ask! is not acceptable\n",
      "The user's question was about whether they have worked on any performance-related tasks and asked for elaboration. However, the AI agent incorrectly assumed the role is about Arun's performance-related tasks instead of responding to the user's question about their own experience. Therefore, there is no exact match between the user's question and the agent's response, making it unacceptable.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stage 3 - Create a rerun and integrate it with the Chat Interface \n",
    "1. Get the response in a format that can be evaluated\n",
    "2. Evaluate the response and give feedback\n",
    "3. Rerun the response if it is not acceptable\n",
    "\"\"\"\n",
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content \n",
    "\n",
    "\n",
    "\n",
    "def chat_with_rerun(message, history):\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    if evaluation.isAcceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(f\"Failed evaluation -  as the reply: {reply} is not acceptable\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat_with_rerun,title=\"Arun's AI Assistant\",description=\"Ask anything about Arun's background and experience.\",type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e1b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f87aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b36bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae6bf21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb98a096",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57052488",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05512d25",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d2dfd58",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4db61270",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda-py-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
